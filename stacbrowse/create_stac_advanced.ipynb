{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create enhanced static stac catalog with added metadata \n",
    "\n",
    "Approach:\n",
    "\n",
    "1. Use Umbra STAC API to find public data + metadata \n",
    "1. Find public GeoTiffs in public S3 bucket (unfortunately not linked in API return!)\n",
    "1. Generate STAC metadata with TiTiler by actually reading GEC file\n",
    "    - we can trust these footprints + adds other information of interest (proj extension, raster extension)\n",
    "1. Add custom metadata we are interested in \n",
    "    - e.g. processor version, RPCs, sar:observation_direction, etc\n",
    "1. Merge Umbra metadata with TiTiler-generated metadata\n",
    "1. Save as a static STAC catalog for easy future referecnce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure we have an updated list of assets\n",
    "#!aws s3 ls --no-sign-request s3://umbra-open-data-catalog/ --recursive > umbra-open-data-catalog-list.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "import urllib.parse\n",
    "import requests\n",
    "import rasterio\n",
    "\n",
    "from pystac.layout import TemplateLayoutStrategy\n",
    "\n",
    "os.environ['AWS_NO_SIGN_REQUEST'] = 'YES'\n",
    "os.environ['GDAL_DISABLE_READDIR_ON_OPEN'] = 'EMPTY_DIR'\n",
    "\n",
    "import geopandas as gpd\n",
    "import pystac_client\n",
    "import stac_geoparquet\n",
    "import pystac\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stac_geoparquet.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Umbra API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi = gpd.read_file('panama-canal.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for acquisitions in AWS Open Data Catalog\n",
    "# NOTE: different endpoint, but still need auth\n",
    "stac_api_url = \"https://api.canopy.umbra.space/archive/\"\n",
    "catalog = pystac_client.Client.open(stac_api_url,\n",
    "                                    headers={\"authorization\": f\"Bearer {os.environ.get('UMBRA_API_TOKEN')}\" }\n",
    ")\n",
    "catalog\n",
    "\n",
    "# Hack fix for broken API links (need to be https://)\n",
    "# https://github.com/huskysar/umbra/issues/1\n",
    "for link in catalog.get_links():\n",
    "    link.target = link.target.replace('http://','https://')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit_results=3000\n",
    "\n",
    "cql2filter = {\n",
    "    \"op\": \"=\",\n",
    "    \"args\": [\n",
    "      {\n",
    "        \"property\": \"umbra:open-data-catalog\"\n",
    "      },\n",
    "      True\n",
    "    ]\n",
    "  }\n",
    "\n",
    "stac_search = catalog.search(\n",
    "    intersects=aoi.geometry.iloc[0],\n",
    "    max_items=limit_results,\n",
    "    limit=limit_results,\n",
    "    collections=[\"umbra-sar\"],\n",
    "    filter=cql2filter,\n",
    ")\n",
    "\n",
    "items = stac_search.item_collection()\n",
    "#stac_search.matched() # doesn't work for umbra\n",
    "len(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 --no-sign-request ls 's3://umbra-open-data-catalog/sar-data/tasks/Panama Canal, Panama/' | wc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hmmm, so there is a mismatch between the number of items found and the number of files in the bucket\n",
    "# Apparently some are also under a 'ship detection' folder, and some are simply missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAC Item ID should be only at top level, not under 'properties'\n",
    "# Still 'valid' according to items[0].validate(), but messes up stac-geoparquet parsing\n",
    "_ = [i.properties.pop('id', None) for i in items]\n",
    "\n",
    "# Warning: older items do not have 'created' or 'updated' fields\n",
    "# STAC geoparquet requires values for all rows in a column, so will add the following to STAC when saved:\n",
    "#\"created\": null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_batch_reader = stac_geoparquet.arrow.parse_stac_items_to_arrow(items)\n",
    "gf = gpd.GeoDataFrame.from_arrow(record_batch_reader)  # doesn't keep arrow dtypes\n",
    "gf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link to public GeoTiff Assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def s3_to_http(s3_path):\n",
    "    # NOTE: titiler requires https:// links\n",
    "    #http://umbra-open-data-catalog.s3.amazonaws.com/sar-data/tasks/Panama%20Canal%2C%20Panama/fac35699-2f8d-4c28-ab5e-638182373f34/2024-02-17-15-00-05_UMBRA-04/2024-02-17-15-00-05_UMBRA-04_GEC.tif\n",
    "    url = s3_path.replace('s3://umbra-open-data-catalog/','https://umbra-open-data-catalog.s3.amazonaws.com/')\n",
    "    #sanitized = urllib.parse.quote(url, safe=':/')\n",
    "    sanitized = urllib.parse.quote_plus(url, safe=':/,') # NOTE: trying to get URLs to work w/ GDAL CLI and TITILER\n",
    "    return sanitized\n",
    "\n",
    "def get_asset_hrefs(task_id, prefix='s3://umbra-open-data-catalog/sar-data'):\n",
    "    \"\"\" extract hrefs for a given umbra:task_id from s3 bucket listing (umbra-open-data-catalog-list.txt) \"\"\"\n",
    "    with open('umbra-open-data-catalog-list.txt') as f:\n",
    "        lines = f.readlines()\n",
    "    assets = [x.rstrip() for x in lines if task_id in x]\n",
    "    asset_paths = [prefix + x.split('sar-data')[1] for x in assets]\n",
    "    return asset_paths\n",
    "\n",
    "\n",
    "def make_asset_dictionary(asset_paths):\n",
    "    \"\"\" assign href based on file name suffix \"\"\"\n",
    "    # NOTE: newer versions will switch to MM.tif\n",
    "    asset_map = {}\n",
    "    for asset in asset_paths:\n",
    "        if asset.endswith('GEC.tif') or asset.endswith('MM.tif'):\n",
    "            asset_map['gec'] = {\n",
    "    \"description\": \"MONOSTATIC TIFF\",\n",
    "    \"href\": s3_to_http(asset),\n",
    "    \"roles\": [\n",
    "        \"data\"\n",
    "    ],\n",
    "    \"title\": \"TIFF\",\n",
    "    \"type\": \"image/tiff; application=geotiff; profile=cloud-optimized\"\n",
    "}\n",
    "        elif asset.endswith('METADATA.json'):\n",
    "            asset_map['metadata'] = {\n",
    "    \"description\": \"MONOSTATIC METADATA\",\n",
    "    \"href\": s3_to_http(asset),\n",
    "    \"roles\": [\n",
    "        \"metadata\"\n",
    "    ],\n",
    "    \"title\": \"METADATA\",\n",
    "    \"type\": \"application/json\"\n",
    "}\n",
    "        elif asset.endswith('SICD.nitf'):\n",
    "            asset_map['sicd'] = {\n",
    "    \"description\": \"MONOSTATIC SICD\",\n",
    "    \"href\": s3_to_http(asset),\n",
    "    \"roles\": [\n",
    "        \"data\"\n",
    "    ],\n",
    "    \"title\": \"SICD\",\n",
    "    \"type\": \"application/octet-stream\"\n",
    "}\n",
    "# Some collects missing SIDD. Need all items to have same assets, so just skip for now\n",
    "# I don't think we need it, and can just replace SICD with SIDD in path if is needed\n",
    "#         elif asset.endswith('SIDD.nitf'):\n",
    "#             asset_map['sidd'] = {\n",
    "#     \"description\": \"MONOSTATIC SIDD\",\n",
    "#     \"href\": asset,\n",
    "#     #or how stac-geoparquet does it: np.array(['data'], dtype=object)\n",
    "#     \"roles\": [\n",
    "#         \"data\"\n",
    "#     ],\n",
    "#     \"title\": \"SIDD\",\n",
    "#     \"type\": \"application/octet-stream\"\n",
    "# }\n",
    "\n",
    "    return asset_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 10 #'234aee0f-59a6-4b57-94f2-e799357b5352' not in there yet!\n",
    "hrefs = get_asset_hrefs(gf['umbra:task_id'].iloc[10])\n",
    "make_asset_dictionary(hrefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Assets\n",
    "gf['assets'] = gf['umbra:task_id'].apply(lambda x: make_asset_dictionary(get_asset_hrefs(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with empty assets\n",
    "gf = gf[gf['assets'].apply(lambda x: len(x) > 0)].reset_index(drop=True)\n",
    "len(gf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gf.assets.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Dataframe back to stac items\n",
    "batch = stac_geoparquet.arrow.stac_table_to_items(gf.to_arrow())\n",
    "items = [pystac.Item.from_dict(x) for x in batch]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Additional Metadata from Tifs and Metadata Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format for TiTiler\n",
    "def get_datetime(row):\n",
    "    start = row.start_datetime.isoformat()\n",
    "    end = row.end_datetime.isoformat()\n",
    "    datestr = f'{start}/{end}'\n",
    "    #print(datestr)\n",
    "    return datestr\n",
    "\n",
    "get_datetime(gf.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#s = gf1.iloc[0]\n",
    "#print(s.start_datetime, s.end_datetime)\n",
    "#(s.end_datetime - s.start_datetime).seconds\n",
    "gf['huskysar:duration'] = gf.apply(lambda row: (row.end_datetime - row.start_datetime).seconds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format for TiTiler\n",
    "def get_duration(row):\n",
    "    start = row.start_datetime.isoformat()\n",
    "    end = row.end_datetime.isoformat()\n",
    "    datestr = f'{start}/{end}'\n",
    "    #print(datestr)\n",
    "    return datestr\n",
    "\n",
    "get_datetime(gf.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change itemIDs to GEC Tif names\n",
    "for i in items:\n",
    "    i.properties['umbra:stac_id'] = i.id\n",
    "    i.id = i.assets['gec'].href.split('/')[-1][:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read GeoTIFF Metadata\n",
    "\n",
    "def get_gtiff_metadata(URL):\n",
    "    with rasterio.open(URL) as src:\n",
    "        gtiff_metadata = src.tags()\n",
    "        if src.rpcs is not None:\n",
    "            has_rpcs = True\n",
    "        else:\n",
    "            has_rpcs = False\n",
    "        return gtiff_metadata.get('PROCESSOR'), has_rpcs\n",
    "\n",
    "get_gtiff_metadata(URL = gf.iloc[10].assets['gec']['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_metadata(url):\n",
    "    r = requests.get(url)\n",
    "    return r.json()\n",
    "\n",
    "meta = read_metadata(gf.iloc[10].assets['metadata']['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta['collects'][0]['sceneSize']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_orbit_state_and_observation_direction(url):\n",
    "    r = requests.get(url)\n",
    "    data = r.json()\n",
    "    orbit_state =  data['collects'][0].get('satelliteTrack').lower()\n",
    "    obs_dir = data['collects'][0].get('observationDirection').lower()\n",
    "    scene_size = data['collects'][0].get('sceneSize')\n",
    "    return orbit_state, obs_dir, scene_size\n",
    "\n",
    "get_orbit_state_and_observation_direction(gf.iloc[10].assets['metadata']['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_urls = gf['assets'].apply(lambda x: x['metadata']['href']).values\n",
    "metadata_urls[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Neat: How to wrap a synchronous function to run asynchronously!\n",
    "# https://www.youtube.com/watch?v=p8tnmEdeOU0\n",
    "async def get_obs_dir_async(url):\n",
    "    response = await asyncio.to_thread(get_orbit_state_and_observation_direction, url)\n",
    "    return response\n",
    "\n",
    "extracted_metadata = await asyncio.gather(*[get_obs_dir_async(url) for url in metadata_urls])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same to get all the processor and has_rpcs\n",
    "# KeyError: 'PROCESSOR'\n",
    "tif_urls = gf['assets'].apply(lambda x: x['gec']['href']).values\n",
    "tif_urls[:3]\n",
    "\n",
    "async def get_tiff_info_async(url):\n",
    "    response = await asyncio.to_thread(get_gtiff_metadata, url)\n",
    "    return response\n",
    "\n",
    "extracted_tifftags = await asyncio.gather(*[get_tiff_info_async(url) for url in tif_urls])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "gf['sar:observation_direction'] = [x[1] for x in extracted_metadata]\n",
    "gf['sat:orbit_state'] = [x[0] for x in extracted_metadata]\n",
    "gf['huskysar:scene_size'] = [x[2] for x in extracted_metadata]\n",
    "gf['umbra:processor'] = [x[0] for x in extracted_tifftags]\n",
    "gf['huskysar:rpcs'] = [x[1] for x in extracted_tifftags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gf.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For now, only work with data that has RPCs\n",
    "gf1 = gf[gf['huskysar:rpcs']].reset_index(drop=True)\n",
    "len(gf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recent processors switched to 5x5 instead of 4x4 default scene size\n",
    "gf1['huskysar:scene_size'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RPCs after 2024-02-01 processor>3.41.0\n",
    "gf1.start_datetime.min(), gf1.end_datetime.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Dataframe back to stac items\n",
    "batch = stac_geoparquet.arrow.stac_table_to_items(gf1.to_arrow())\n",
    "orig_items = [pystac.Item.from_dict(x) for x in batch]\n",
    "len(orig_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use TiTiler to generate STAC metadata directly from TIFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "URL = gf.iloc[i].assets['gec']['href']\n",
    "ID = URL.split('/')[-1][:-4]\n",
    "DATETIME = get_datetime(gf.iloc[i])\n",
    "\n",
    "# https://titiler.xyz/api.html#/\n",
    "# r = requests.get(\"https://titiler.xyz/cog/stac?asset_name=data&asset_media_type=auto&with_proj=true&with_raster=true&with_eo=true&max_size=1024&geometry_densify=0&geometry_precision=-1&url=http%3A%2F%2Fumbra-open-data-catalog.s3.amazonaws.com%2Fsar-data%2Ftasks%2FPanama%2520Canal%252C%2520Panama%2Fbfe9e972-3bf2-4da4-b9f2-24fd8f54d157%2F2025-01-13-03-36-19_UMBRA-09%2F2025-01-13-03-36-19_UMBRA-09_GEC.tif\")\n",
    "baseurl = \"https://titiler.xyz/cog/stac\"\n",
    "params = {\"id\": ID,\n",
    "    \"asset_name\": \"data\",\n",
    "            \"collection\": \"umbra-sar\",\n",
    "            \"datetime\": DATETIME,\n",
    "            \"asset_media_type\": \"auto\",\n",
    "            \"with_proj\": \"true\",\n",
    "            \"with_raster\": \"true\",\n",
    "            \"with_eo\": \"true\",\n",
    "            #\"max_size\": \"1024\",\n",
    "            \"geometry_densify\": \"0\",\n",
    "            \"geometry_precision\": \"-1\",\n",
    "            \"url\": URL}\n",
    "r = requests.get(baseurl, params=params)\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How does the above compare to UMBRA API STAC?\n",
    "\n",
    "```\n",
    "#items[0].to_dict() # unathorized!\n",
    "#gf.iloc[0].to_dict()\n",
    "```\n",
    "\n",
    "A few observations:\n",
    "\n",
    "1. Umbra uses POLYGONZ (with heights (from where?...))\n",
    " 'geometry': <POLYGON Z ((-79.558 8.996 14.315, -79.604 8.996 14.316, -79.604 8.951 14.31...>,\n",
    "1. Umbra bbox approx equivalent (given 5 decimals ~ +/- 1m 6-> +/-cm)\n",
    "s = [-79.60429181215505, 8.950889800680791, -79.55847377933229, 8.99644461237005],\n",
    "u = [-79.60429112089089, 8.950889110300890, -79.55847308842013, 8.996443921817997]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate STAC with TiTiler (actually read the GeoTiff)\n",
    "# This will add additional detail like 'proj' and 'raster' extension information &datetime={datetime} id={id} collection={collection}&asset_name={asset_name}&asset_roles=data&\n",
    "def create_stac_item(row):\n",
    "    baseurl = \"https://titiler.xyz/cog/stac\"\n",
    "\n",
    "    URL = row.assets['gec']['href']\n",
    "    ID = URL.split('/')[-1][:-4]\n",
    "    # Just omit this b/c will merge w/ original metadata\n",
    "    #DATETIME = get_datetime(row)\n",
    "\n",
    "    params = {\"id\": ID,\n",
    "              \"asset_name\": \"gec\",\n",
    "              \"asset_media_type\": \"image/tiff; application=geotiff; profile=cloud-optimized\",\n",
    "              \"asset_roles\": [\"data\"],\n",
    "                #\"collection\": \"umbra-sar\", # leave out for now (needs a 'self' link)\n",
    "                #\"datetime\": DATETIME,\n",
    "                #\"asset_media_type\": \"auto\",\n",
    "                \"with_proj\": \"true\",\n",
    "                \"with_raster\": \"true\",\n",
    "                \"with_eo\": \"false\",\n",
    "                #\"max_size\": \"1024\",\n",
    "                \"geometry_densify\": \"0\",\n",
    "                \"geometry_precision\": \"-1\",\n",
    "                \"url\": URL}\n",
    "    r = requests.get(baseurl, params=params)\n",
    "    return r.json()\n",
    "\n",
    "stac = create_stac_item(gf.iloc[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate all the STAC ITEMS\n",
    "async def create_stac_async(row):\n",
    "    response = await asyncio.to_thread(create_stac_item, row)\n",
    "    return response\n",
    "\n",
    "stac_items = await asyncio.gather(*[create_stac_async(row) for i,row in gf1.iterrows()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as a single item collection\n",
    "#itemCollection = pystac.ItemCollection(stac_items)\n",
    "#itemCollection.save_object('panama_timeseries_riostac.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stac_items[0]['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with original STAC\n",
    "# Really just want additional properties\n",
    "#stac_items[0]['properties'].update(orig_items[0].properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new = set(stac_items[1]['properties'].keys())\n",
    "# orig = set(orig_items[1].properties.keys())\n",
    "# new.difference(orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# orig.difference(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new.intersection(orig) # only one in common is 'datetime'! (which is None since we have start/end instead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add original properites to all the items\n",
    "for i in range(len(stac_items)):\n",
    "    stac_items[i]['properties'].update(orig_items[i].properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "publish_items = [pystac.Item.from_dict(x) for x in stac_items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "publish_items[0] # NOTE: no links at all!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative save with a different layout\n",
    "# NOTE: to *browse* by year would actually have to save annual subcatalogs (or collections?)\n",
    "#from pystac.layout import TemplateLayoutStrategy\n",
    "catalog = pystac.Catalog(id='panama-canal', description='Umbra Open SAR Data over Panama Canal')\n",
    "catalog.add_items(publish_items)\n",
    "\n",
    "strategy = TemplateLayoutStrategy(item_template=\"${year}\")\n",
    "#catalog.normalize_hrefs('panama-canal-byyear', strategy=strategy)\n",
    "catalog.normalize_hrefs('./panama-canal-gec', strategy=strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog.save(catalog_type=pystac.CatalogType.SELF_CONTAINED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also save single, consolidated item collection\n",
    "itemCollection = pystac.ItemCollection(publish_items)\n",
    "itemCollection.save_object('panama-canal-gec.geojson')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
